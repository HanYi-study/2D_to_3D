# 2d转3d的方法总结与对比

## 基于vision transformer架构的单目深度估计模型
使用的模型是DPT（Dense Prediction Transformer）模型
- 本质：基于 Vision Transformer（ViT）的单目深度估计模型。
- 输入：单张 RGB 图像。
- 输出：每个像素的深度值（深度图）。
- 主要功能：从单张图片直接预测场景的深度信息，适用于单目深度估计任务。
- 应用流程：深度图 → 点云 → 三维重建。

## 基于光照和灰度变化的 Shape from Shading（SFS）方法
使用的模型是MSGF-SFS（Multi-Scale Gradient Field Shape from Shading）模型
- 本质：一种基于光照和灰度变化的 Shape from Shading（SFS）方法。
- 输入：单张灰度或彩色图像，通常假设已知光照条件。
- 输出：物体表面的法向量场或深度图。
- 主要功能：通过分析图像的灰度变化和光照信息，推断物体表面的三维形状（通常是法向量或高度图）。
- 特点：MSGF-SFS 通过多尺度梯度场建模，提升了对细节和噪声的鲁棒性，适合细致表面重建。


> DPT与MSGF-SFS的区别：
>
| 方面 |	DPT（Transformer）单目深度估计 |	MSGF-SFS（Shape from Shading） |  
|--------|-------------------------------|--------------------------------|  
| 原理 |	深度学习，Transformer架构 |	传统图像处理，基于光照建模 |  
| 输入	| 单张RGB图像 |	单张图像+光照假设 |  
| 输出	| 深度图 | 	法向量场/深度图 |  
| 依赖 |	大规模数据训练 |	物理光照模型 |  
| 优势 |	适应性强，泛化能力好 |	对细节敏感，适合精细表面 |  
| 应用 |	通用场景深度估计 |	需要已知或可估计光照的场景 |  
